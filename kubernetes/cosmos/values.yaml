pfsd:
  enabled: true
  name: pfsd

  replicaCount: 1
  readOnly: false

  image:
    repository: zenko/cloudserver
    tag: 8.1.5
    pullPolicy: IfNotPresent

  service:
    ## Override the generated service name.
    # name: ""

    type: ClusterIP
    port: 80

  ## Enable file syncing. If set to 'true', files will not be synced to ensure
  ## that they are written to disk. Also, it will not be guranteed that page
  ## caches will be released by the Kernel when 'noCache' is 'true'
  noSync: false

  ## Enable Kernel page caching. If set to 'true', page caches will be released
  ## after reading or writing files using posix_fadvise(POSIX_FADV_DONTNEED)
  ## This prevents virtual memory size from increasing proportinally to the files
  ## read or written.
  noCache: true

  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}

rclone:
  name: rclone
  command: sync
  mdOnly: true

  image:
    repository: zenko/rclone
    tag: 1.45.3
    pullPolicy: IfNotPresent

  ## Used to manually trigger ingestion
  triggerIngestion: true
  ## CronJob options
  suspend: false
  schedule: "0 */12 * * *"
  successfulJobsHistory: 1

  ## Specify source details
  ## Currently only local fs via PersistentVolumes is supported
  source:
    type: local
    nounc: true
    copy_links: false
    ## Specify an existing secret to get credentials from.
    # existingSecret: ""

  ## Specify destination details
  ## Currently only local s3 compatible is supported
  destination:
    type: s3
    ## Provider can be AWS or Other
    provider: Other
    acl: bucket-owner-full-control
    ## Specify an existing secret to get credentials from.
    # existingSercret: ""
    ## Otherwise use the following credentials.
    access_key_id: my-access-key
    secret_access_key: my-secret-key

    endpoint: http://zenko-cloudserver
    region: mynfs
    bucket: newbucket

  ## Any valid rclone cli option can be passed as a key:value pair
  options:
    ## These values are optimized for higher throughput however if needed they
    ## can be modified for specific workloads or commented out all together
    ## if necessary and will revert to the defaults
    cache-workers: 32 # Default is 4
    s3-upload-concurrency: 32 # Default is 2
    transfers: 32 # Default is 4
    checkers: 64 # Default 8

  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}

persistentVolume:
  enabled: false
  ## Specifiy a existing storage class to use
  # storageClass:
  ## Specify existing PVC to use
  # existingClaim:
  volumeConfig: {}
    ## Example NFS config
    # nfs:
    #   server: 10.100.1.42
    #   path: /data
    #   readOnly: false
    # mountOptions:
    # - hard
    # - nfsvers=4.1
  accessModes:
    - ReadWriteMany
  size: 1Gi
