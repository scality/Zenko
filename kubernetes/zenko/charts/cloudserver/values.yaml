# Default values for cloudserver.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

global:
  orbit:
    enabled: true
    endpoint: https://api.zenko.io
    pushEndpoint: https://push.api.zenko.io
    managerMode: push
    workerMode: push
    storageLimit:
      # This allows you to manage storage limits from Orbit
      enabled: true

  # When 'orbit.enabled' is 'true', these aren't used, please use
  # https://zenko.io to manage your deployment
  locationConstraints: {}
    # awsbackend:
    #   type: aws_s3
    #   legacyAwsBehavior: true
    #   details:
    #     bucketMatch: true
    #     awsEndpoint: s3.amazonaws.com
    #     bucketName:
    #     credentials:
    #       accessKey:
    #       secretKey:
    # azurebackend:
    #   type: azure
    #   legacyAwsBehavior: true
    #   details:
    #     bucketMatch: false
    #     azureStorageEndpoint: https://example.blob.core.windows.net
    #     azureStorageAccountName:
    #     azureStorageAccessKey:
    #     azureContainerName:
    # gcpbackend:
    #   type: gcp
    #   legacyAwsBehavior: true
    #   details:
    #     bucketMatch: false
    #     gcpEndpoint: storage.googleapis.com
    #     bucketName:
    #     mpuBucketName:
    #     credentials:
    #       accessKey:
    #       secretKey:
  replicationEndpoints: []
    # - awsbackend
    # - azurebackend
    # - gcpbackend

# backends level keep-alive config
externalBackends:
  aws_s3:
    keepAlive: false
    keepAliveMsecs: 1000
    maxFreeSockets: 256
    maxSockets: null
  gcp:
    keepAlive: true
    keepAliveMsecs: 1000
    maxFreeSockets: 256
    maxSockets: null

endpoint: zenko.local

users: {}
  # accountName:
    # access:
    # secret:

logging:
   # Options: info, debug, trace
   level: info

allowHealthchecksFrom: '0.0.0.0/0'

env: {}

mongodb:
  replicaSet: rs0
  replicas: 3

redis:
  sentinel:
    name: zenko
  replicas: 3

# Replication factor will deploy n * replicaCount for deployments that need
# not only HA but high performance and throughput. When Orbit is enabled, there
# will be an additional stateless single manager pod deployed which serves as the
# "manager" for reporting metrics. This manager pod currently cannot scale replicas.
replicaCount: 3
replicaFactor: 1

image:
  repository: zenko/cloudserver
  tag: 8.0.20
  pullPolicy: IfNotPresent

proxy:
  # If you want to use an HTTP proxy, add the respective endpoints after
  # 'http:' and/or 'https:'. If the HTTP proxy endpoint is set but the HTTPS
  # one isn't, the HTTP proxy will be used for HTTPS traffic as well.
  # Additionally you can pass a CA certifcate that will be added to the trusted
  # certs. If the proxy URL is configured and caCert is true, helm
  # will look for a file named 'ca.crt' at the root path of this chart.
  # Note: To avoid unexpected behavior, only specify one of "http" or "https"
  # proxy options.
  # If you have exceptions to proxification you can use the no_proxy variable.
  http: ""
  https: ""
  caCert: false
  no_proxy: ""

service:
  type: ClusterIP
  port: 80
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8000"
    prometheus.io/path: "/_/monitoring/metrics"

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  path: /
  # This must match 'endpoint', unless your client supports different
  # hostnames.
  hosts:
    - zenko.local
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

nodeSelector: {}

tolerations: []

# These default settings are for a "soft" anti affinity scheduling
# where the deployment of replicas will try to be scheduled on different
# nodes in the cluster. This can be customized to user specific values.
# https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
affinity: |
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 5
      podAffinityTerm:
        topologyKey: "kubernetes.io/hostname"
        labelSelector:
          matchLabels:
            app: {{ template "cloudserver.name" . }}
            release: {{ .Release.Name | quote }}

autoscaling:
  enabled: false
  config:
    minReplicas: 1
    maxReplicas: 16
    # Note: when setting this, a `resources.request.cpu` is required. You
    # likely want to set it to `1` or some lower value.
    targetCPUUtilizationPercentage: 80
