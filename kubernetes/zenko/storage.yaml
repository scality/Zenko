## These values can be used to override the storage and persistence options of
## all the stateful charts used in Zenko. While all the options listed are the
## default values, this file can be changed and applied only at chart
## installation time by specifying `-f storage.yaml`. Values cannot be changed
## post installation.

mongodb-replicaset:
  ## Notes:
  ##   - number of PVs required is `nodeCount`
  ##   - Sizing is generally based off max object counts
  ##     e.g. (Number of objects * 0.01) MB is typically used for sizing
  ##     objects with the default amount of metadata
  ##
  persistentVolume:
    enabled: true
    ## mongodb-replicaset data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: null
    ## Must match those of existing PV or dynamic provisioner
    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    accessModes:
      - ReadWriteOnce
    size: 10Gi
    annotations: {}

prometheus:
  server:
    ## Notes:
    ##   - number of PVs required is 2 by default
    ##   - This is used for storing application level metrics
    ##   - Retention policies will attempt to keep 15 days worth of metrics
    ##     if the volume isn't full
    ##
    persistentVolume:
      enabled: true
      accessModes:
        - ReadWriteOnce
      annotations: {}
      mountPath: /data
      size: 8Gi
      storageClass: null
      ## Subdirectory of Prometheus server data Persistent Volume to mount
      ## Useful if the volume's root directory is not empty
      ##
      subPath: ""

redis-ha:
  ## Notes:
  ##   - number of PVs required is `nodeCount`
  ##   - in-memory key-value store vital to the replication services
  ##
  persistentVolume:
    enabled: true
    storageClass: null
    accessModes:
      - ReadWriteOnce
    size: 10Gi
    annotations: {}

s3-data:
  ## Notes: 
  ##   - number of PVs required is 1
  ##   - this storage is used for the Zenko localCache and is used for the data
  ##     that can stored locally prior to replication to an external resource
  ##   - storing files locally on Zenko is mostly limited by the s3-data volume
  ##
  persistentVolume:
    enabled: true
    accessModes:
      - ReadWriteOnce
    annotations: {}
    existingClaim: ""
    size: 10Gi
    storageClass: null
 
zenko-queue:
  ## Notes:
  ##   - number of PVs required is `nodeCount`
  ##   - Rention is 7 days by default which will generally use at least 300MB
  ##     per pod for lighter work loads
  ##
  persistence:
    enabled: true
    ## The size of the PersistentVolume to allocate to each Kafka Pod in the
    ## StatefulSet. For production servers this should be much larger.
    ##
    size: "1Gi"
    ## The location within the Kafka container where the PV will mount its
    ## storage and Kafka will store its logs.
    ##
    mountPath: "/opt/kafka/data"
    storageClass: null

zenko-quorum:
  ## Notes:
  ##   - number of PVs required is `nodeCount`
  ##   - disk performance is vital here and SSD drives are highly recommended
  ##   - In general 64GB is the minimum recommended for production deployments
  ##
  persistence:
    enabled: true
    storageClass: null
    accessMode: ReadWriteOnce
    size: 5Gi
